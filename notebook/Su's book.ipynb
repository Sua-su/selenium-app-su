{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"\n",
    "\n",
    "import time\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(f\"--user-agnet={user_agent}\")\n",
    "browser = webdriver.Chrome(chrome_options)\n",
    "\n",
    "query = \"MLB\"\n",
    "url = f\"https://search.naver.com/search.naver?where=news&query={query}\"\n",
    "browser.get(url)\n",
    "\n",
    "browser.maximize_window()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "title = browser.title\n",
    "page_sourse = browser.page_source\n",
    "\n",
    "\n",
    "browser.save_screenshot(\"PAGE.jpg\")\n",
    "page_sourse = browser.page_source\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLB : 네이버 뉴스검색\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' thumb_box = soup.select(\".thumb_box\")\\n\\nfor dix , thumb_box in enumerate(thumb_box , 1):\\n    name = thumb_box.select_one(\".info press\")\\n    thum = thumb_box.select_one(\".thumb\")\\n    print(name)\\n    # print(thumb_box, name.get_text() , name[\"\"])\\n\\npass\\n '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page_sourse)\n",
    "news_contents = soup.select(\".news_contents\")\n",
    "\n",
    "\"\"\" for news, idx in enumerate(news_contents, 1):\n",
    "    print(news,idx) \"\"\"\n",
    "#웹페이지 cotents 가져오는 코드\n",
    "# print(len( news_contents))\n",
    "for idx , news_content in enumerate(news_contents , 1):\n",
    "    title = news_content.select_one(\".news_tit\")\n",
    "    description = news_content.select_one(\".dsc_txt_wrap\")\n",
    "    # print(idx, title.get_text() , title[\"href\"])\n",
    "    # print(description.get_text() )\n",
    "    info_group = news_content.select_one(\".info_group\")\n",
    "    print(info_group)\n",
    "\n",
    "\"\"\" \n",
    "dsc_txt_wrap\n",
    " \"\"\"   \n",
    "\"\"\" thumb_box = soup.select(\".thumb_box\")\n",
    "\n",
    "for dix , thumb_box in enumerate(thumb_box , 1):\n",
    "    name = thumb_box.select_one(\".info press\")\n",
    "    thum = thumb_box.select_one(\".thumb\")\n",
    "    print(name)\n",
    "    # print(thumb_box, name.get_text() , name[\"\"])\n",
    "    \n",
    "pass\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<div class=\"news_wrap api_ani_send\"> <div class=\"news_area\"> <div class=\"news_info\"> <div class=\"api_save_group _keep_wrap\"> <a aria-pressed=\"false\" class=\"btn_save _keep_trigger\" data-url=\"https://www.yna.co.kr/view/AKR20250325132500007?input=1195m\" href=\"#\" onclick=\"tCR('a=nws*a.kep&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;u=javascript'); return false;\" role=\"button\"><i class=\"spnew ico_save\">문서 저장하기</i></a> <div class=\"api_ly_save _keep_save_layer\"> <a class=\"spnew_af item item_save _keep_save\" data-cr-off=\"a=nws*a.kepoff&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;u=javascript\" data-cr-on=\"a=nws*a.kepon&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;u=javascript\" href=\"#\" role=\"button\">Keep에 저장</a> <a class=\"spnew_af item item_quick\" href=\"https://keep.naver.com/\" onclick=\"return goOtherCR(this,'a=nws*a.kephome&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;u='+urlencode(this.href));\" target=\"_blank\">Keep 바로가기</a> </div></div><div class=\"info_group\"> <a class=\"info press\" href=\"https://www.yna.co.kr/\" onclick=\"return goOtherCR(this, 'a=nws*a.prof&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;g=001.0015288918&amp;u='+urlencode(this.href));\" target=\"_blank\"><span class=\"thumb_box\"><img alt=\"\" class=\"thumb\" height=\"24\" onerror=\"this.src='data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7';this.className='thumb bg_default_press'\" src=\"https://search.pstatic.net/common/?src=https%3A%2F%2Fmimgnews.pstatic.net%2Fimage%2Fupload%2Foffice_logo%2F001%2F2017%2F06%2F29%2Flogo_001_18_20170629160329.png&amp;type=f54_54&amp;expire=24&amp;refresh=true\" width=\"24\"/></span>연합뉴스</a><span class=\"info\">6시간 전</span><a class=\"info\" href=\"https://m.sports.naver.com/wbaseball/article/001/0015288918\" onclick=\"return goOtherCR(this, 'a=nws*a.nav&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;u='+urlencode(this.href));\" target=\"_blank\">네이버뉴스</a> </div></div><div class=\"news_contents\"> <a class=\"dsc_thumb\" href=\"https://www.yna.co.kr/view/AKR20250325132500007?input=1195m\" onclick=\"return goOtherCR(this, 'a=nws*a.img&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;g=001.0015288918&amp;u='+urlencode(this.href));\" target=\"_blank\"><img alt=\"이정후는 MLB 개막전부\" class=\"thumb\" height=\"104\" onerror=\"this.parentNode.style.display='none';\" src=\"https://search.pstatic.net/common/?src=https%3A%2F%2Fimgnews.pstatic.net%2Fimage%2Forigin%2F001%2F2025%2F03%2F26%2F15288918.jpg&amp;type=f200_200&amp;expire=2&amp;refresh=true\" width=\"104\"/></a> <a class=\"news_tit\" href=\"https://www.yna.co.kr/view/AKR20250325132500007?input=1195m\" onclick=\"return goOtherCR(this, 'a=nws*a.tit&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;g=001.0015288918&amp;u='+urlencode(this.href));\" target=\"_blank\" title=\"이정후는 MLB 개막전부터…김하성·김혜성은 때를 기다린다\">이정후는 <mark>MLB</mark> 개막전부터…김하성·김혜성은 때를 기다린다</a> <div class=\"news_dsc\"> <div class=\"dsc_wrap\"> <a class=\"api_txt_lines dsc_txt_wrap\" href=\"https://www.yna.co.kr/view/AKR20250325132500007?input=1195m\" onclick=\"return goOtherCR(this, 'a=nws*a.body&amp;r=1&amp;i=880000D8_000000000000000015288918&amp;g=001.0015288918&amp;u='+urlencode(this.href));\" target=\"_blank\">메이저리그(<mark>MLB</mark>)가 28일(한국시간) 미국 본토 개막전으로 6개월의 장기 레이스를 시작한다. 로스앤젤레스 다저스와 시카고 컵스는 지난 18일과 19일 일본 도쿄돔에서 <mark>MLB</mark> 공식 정규리그 개막 2연전을 치렀다. 미국 본토에서 정규리그 첫 경기가 열리는 날은 28일이다. 아직 30개 구단 개막 엔트리(팀당 26명)가...</a> </div></div></div></div></div>\n",
      "뉴스 제목 :  이정후는 MLB 개막전부터…김하성·김혜성은 때를 기다린다\n",
      "뉴스 설명 :  https://www.yna.co.kr/view/AKR20250325132500007?input=1195m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute \"select_one\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m뉴스 설명 : \u001b[39m\u001b[33m'\u001b[39m ,news_href)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# news_info = news.select_one(\".info press\")\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# print(news_info.get_text())\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m news_name = \u001b[43mnews_icon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_one\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m.info\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m뉴스 아이콘: \u001b[39m\u001b[33m'\u001b[39m , news_name.get_text())\n\u001b[32m     24\u001b[39m news_thumb = news_icon[\u001b[33m\"\u001b[39m\u001b[33m.thumb_box\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/selenium-app/env/lib/python3.13/site-packages/bs4/element.py:2877\u001b[39m, in \u001b[36mResultSet.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2875\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2876\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2877\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   2878\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mResultSet object has no attribute \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m. You\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2879\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: ResultSet object has no attribute \"select_one\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page_sourse)\n",
    "news_list = soup.select(\".news_wrap\")\n",
    "news_content = soup.select(\".news_contents\")\n",
    "news_icon = soup.select(\".info_group\")\n",
    "#news_icon = news_infogroup in soup.select_one(\".info\")\n",
    "\n",
    "for idx ,news in enumerate(news_list , 1):\n",
    "    print(idx)\n",
    "    \"\"\" title = news.select_one(\".news_tit\") \"\"\"\n",
    "    print(news)\n",
    "    news_title = news.select_one(\".news_tit\")\n",
    "    print('뉴스 제목 : ' , news_title.get_text())\n",
    "    \n",
    "    news_href = news_title[\"href\"]   # [ ] <-- 그냥 가져옴 궁금하면 class 적으셈\n",
    "    print('뉴스 설명 : ' ,news_href)\n",
    "    \n",
    "    # news_info = news.select_one(\".info press\")\n",
    "    # print(news_info.get_text())\n",
    "\n",
    "    news_name = news_icon.select_one(\".info\")\n",
    "    print('뉴스 아이콘: ' , news_name.get_text())\n",
    "\n",
    "    news_thumb = news_icon[\".thumb_box\"]\n",
    "    print('뉴스 로고 : ' , news_thumb)\n",
    "\n",
    "     \n",
    "\n",
    "    \n",
    "#print(news)\n",
    "\"\"\" for box in boxs:\n",
    "    print(box) \"\"\"\n",
    "# bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.naver.com/search.naver?ssc=tab.news.all&amp;where=news&amp;sm=tab_jum&amp;query=MLB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/_mbrx3ld26zbl0ybmcmjn76w0000gn/T/ipykernel_24859/1776407365.py:3: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup= BeautifulSoup(\"https://search.naver.com/search.naver?ssc=tab.news.all&where=news&sm=tab_jum&query=MLB\")\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup= BeautifulSoup(\"https://search.naver.com/search.naver?ssc=tab.news.all&where=news&sm=tab_jum&query=MLB\")\n",
    "print(soup.prettify())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
